"use strict";(self.webpackChunkdoris_website=self.webpackChunkdoris_website||[]).push([["989513"],{92535:function(e,r,n){n.r(r),n.d(r,{default:()=>h,frontMatter:()=>s,metadata:()=>t,assets:()=>l,toc:()=>c,contentTitle:()=>a});var t=JSON.parse('{"id":"db-connect/arrow-flight-sql-connect","title":"Connecting by Arrow Flight SQL Protocol","description":"\x3c!--","source":"@site/docs/db-connect/arrow-flight-sql-connect.md","sourceDirName":"db-connect","slug":"/db-connect/arrow-flight-sql-connect","permalink":"/docs/dev/db-connect/arrow-flight-sql-connect","draft":false,"unlisted":false,"tags":[],"version":"current","frontMatter":{"title":"Connecting by Arrow Flight SQL Protocol","language":"en"},"sidebar":"docs","previous":{"title":"Connecting by MySQL Protocol","permalink":"/docs/dev/db-connect/database-connect"},"next":{"title":"Overview","permalink":"/docs/dev/table-design/overview"}}'),o=n("785893"),i=n("250065");let s={title:"Connecting by Arrow Flight SQL Protocol",language:"en"},a=void 0,l={},c=[{value:"Implementation Principle",id:"implementation-principle",level:2},{value:"Python Usage",id:"python-usage",level:2},{value:"Install Library",id:"install-library",level:3},{value:"Connect to Doris",id:"connect-to-doris",level:3},{value:"Create a table and get metadata",id:"create-a-table-and-get-metadata",level:3},{value:"Import data",id:"import-data",level:3},{value:"Execute a query",id:"execute-a-query",level:3},{value:"Complete code",id:"complete-code",level:3},{value:"Jdbc Connector with Arrow Flight SQL",id:"jdbc-connector-with-arrow-flight-sql",level:2},{value:"Java Usage",id:"java-usage",level:2},{value:"ADBC Driver",id:"adbc-driver",level:3},{value:"JDBC Driver",id:"jdbc-driver",level:3},{value:"Choice of Jdbc and Java connection methods",id:"choice-of-jdbc-and-java-connection-methods",level:3},{value:"Interaction with other big data components",id:"interaction-with-other-big-data-components",level:2},{value:"Spark &amp; \u200B\u200BFlink",id:"spark--flink",level:3},{value:"Support BI tools",id:"support-bi-tools",level:3},{value:"Extended Application",id:"extended-application",level:2},{value:"Multiple BEs return results in parallel",id:"multiple-bes-return-results-in-parallel",level:3},{value:"Multiple BEs share the same IP accessible from outside the cluster",id:"multiple-bes-share-the-same-ip-accessible-from-outside-the-cluster",level:3},{value:"FAQ",id:"faq",level:2},{value:"Release Note",id:"release-note",level:2},{value:"v2.1.9",id:"v219",level:3},{value:"v2.1.8",id:"v218",level:3},{value:"v2.1.7",id:"v217",level:3},{value:"v2.1.6",id:"v216",level:3},{value:"v2.1.5",id:"v215",level:3},{value:"Doris Arrow Flight v2.1.4 and earlier versions are not perfect. It is recommended to upgrade before use.",id:"doris-arrow-flight-v214-and-earlier-versions-are-not-perfect-it-is-recommended-to-upgrade-before-use",level:3}];function d(e){let r={a:"a",blockquote:"blockquote",code:"code",h2:"h2",h3:"h3",img:"img",li:"li",ol:"ol",p:"p",pre:"pre",ul:"ul",...(0,i.a)(),...e.components};return(0,o.jsxs)(o.Fragment,{children:[(0,o.jsx)(r.p,{children:"Since Doris 2.1, a high-speed data link based on the Arrow Flight SQL protocol has been implemented, allowing SQL queries to rapidly retrieve large volumes of data from Doris in multiple languages. Arrow Flight SQL also provides a universal JDBC driver, supporting seamless interaction with databases that also follow the Arrow Flight SQL protocol. In some scenarios, performance can improve by up to a hundred times compared to data transfer solutions using MySQL Client or JDBC/ODBC drivers."}),"\n",(0,o.jsx)(r.h2,{id:"implementation-principle",children:"Implementation Principle"}),"\n",(0,o.jsx)(r.p,{children:"In Doris, query results are organized in columnar format as Blocks. In versions prior to 2.1, data could be transferred to the target client via MySQL Client or JDBC/ODBC drivers, but this required deserializing row-based Bytes into columnar format. By building a high-speed data transfer link based on Arrow Flight SQL, if the target client also supports Arrow columnar format, the entire transfer process avoids serialization and deserialization operations, completely eliminating the time and performance overhead associated with them."}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.img,{alt:"Arrow_Flight_SQL",src:n(347174).Z+"",width:"1280",height:"647"})}),"\n",(0,o.jsxs)(r.p,{children:["To install Apache Arrow, you can find detailed installation instructions in the official documentation ",(0,o.jsx)(r.a,{href:"https://arrow.apache.org/install/",children:"Apache Arrow"}),". For more information on how Doris implements the Arrow Flight protocol, you can refer to ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/issues/25514",children:"Doris support Arrow Flight SQL protocol"}),"."]}),"\n",(0,o.jsx)(r.h2,{id:"python-usage",children:"Python Usage"}),"\n",(0,o.jsx)(r.p,{children:"Use Python's ADBC \u200B\u200BDriver to connect to Doris to achieve extremely fast data reading. The following steps use Python (version >= 3.9) ADBC \u200B\u200BDriver to perform a series of common database syntax operations, including DDL, DML, setting Session variables, and Show statements."}),"\n",(0,o.jsx)(r.h3,{id:"install-library",children:"Install Library"}),"\n",(0,o.jsx)(r.p,{children:"The library is published on PyPI and can be easily installed in the following ways:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"pip install adbc_driver_manager\npip install adbc_driver_flightsql\n"})}),"\n",(0,o.jsx)(r.p,{children:"Import the following modules/libraries in the code to use the installed Library:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Python",children:"import adbc_driver_manager\nimport adbc_driver_flightsql.dbapi as flight_sql\n\n>>> print(adbc_driver_manager.__version__)\n1.1.0\n>>> print(adbc_driver_flightsql.__version__)\n1.1.0\n"})}),"\n",(0,o.jsx)(r.h3,{id:"connect-to-doris",children:"Connect to Doris"}),"\n",(0,o.jsx)(r.p,{children:"Create a client to interact with the Doris Arrow Flight SQL service. You need to provide Doris FE's Host, Arrow Flight Port, login username and password, and perform the following configuration.\nModify the configuration parameters of Doris FE and BE:"}),"\n",(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsx)(r.li,{children:"Modify arrow_flight_sql_port in fe/conf/fe.conf to an available port, such as 9090."}),"\n",(0,o.jsx)(r.li,{children:"Modify arrow_flight_sql_port in be/conf/be.conf to an available port, such as 9091."}),"\n"]}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.code,{children:"Note: The arrow_flight_sql_port port number configured in fe.conf and be.conf is different"})}),"\n",(0,o.jsxs)(r.p,{children:["After modifying the configuration and restarting the cluster, searching for ",(0,o.jsx)(r.code,{children:"Arrow Flight SQL service is started"})," in the fe/log/fe.log file indicates that the Arrow Flight Server of FE has been successfully started; searching for ",(0,o.jsx)(r.code,{children:"Arrow Flight Service bind to host"})," in the be/log/be.INFO file indicates that the Arrow Flight Server of BE has been successfully started."]}),"\n",(0,o.jsx)(r.p,{children:'Assuming that the Arrow Flight SQL services of FE and BE in the Doris instance will run on ports 9090 and 9091 respectively, and the Doris username/password is "user"/"pass", the connection process is as follows:'}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Python",children:'conn = flight_sql.connect(uri="grpc://{FE_HOST}:{fe.conf:arrow_flight_sql_port}", db_kwargs={\n            adbc_driver_manager.DatabaseOptions.USERNAME.value: "user",\n            adbc_driver_manager.DatabaseOptions.PASSWORD.value: "pass",\n        })\ncursor = conn.cursor()\n'})}),"\n",(0,o.jsx)(r.p,{children:"After the connection is completed, the returned Cursor can be used to interact with Doris through SQL to perform operations such as creating tables, obtaining metadata, importing data, and querying."}),"\n",(0,o.jsx)(r.h3,{id:"create-a-table-and-get-metadata",children:"Create a table and get metadata"}),"\n",(0,o.jsx)(r.p,{children:"Pass Query to the cursor.execute() function to execute the table creation and metadata acquisition operations:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Python",children:'cursor.execute("DROP DATABASE IF EXISTS arrow_flight_sql FORCE;")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("create database arrow_flight_sql;")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("show databases;")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("use arrow_flight_sql;")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("""CREATE TABLE arrow_flight_sql_test\n    (\n         k0 INT,\n         k1 DOUBLE,\n         K2 varchar(32) NULL DEFAULT "" COMMENT "",\n         k3 DECIMAL(27,9) DEFAULT "0",\n         k4 BIGINT NULL DEFAULT \'10\',\n         k5 DATE,\n    )\n    DISTRIBUTED BY HASH(k5) BUCKETS 5\n    PROPERTIES("replication_num" = "1");""")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("show create table arrow_flight_sql_test;")\nprint(cursor.fetchallarrow().to_pandas())\n'})}),"\n",(0,o.jsx)(r.p,{children:"If StatusResult returns 0, it means that the Query is executed successfully (the reason for this design is to be compatible with JDBC)."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"  StatusResult\n0            0\n\n  StatusResult\n0            0\n\n                   Database\n0         __internal_schema\n1          arrow_flight_sql\n..                      ...\n507             udf_auth_db\n\n[508 rows x 1 columns]\n\n  StatusResult\n0            0\n\n  StatusResult\n0            0\n                   Table                                       Create Table\n0  arrow_flight_sql_test  CREATE TABLE `arrow_flight_sql_test` (\\n  `k0`...\n"})}),"\n",(0,o.jsx)(r.h3,{id:"import-data",children:"Import data"}),"\n",(0,o.jsx)(r.p,{children:"Execute INSERT INTO to import a small amount of test data into the created table:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Python",children:"cursor.execute(\"\"\"INSERT INTO arrow_flight_sql_test VALUES\n        ('0', 0.1, \"ID\", 0.0001, 9999999999, '2023-10-21'),\n        ('1', 0.20, \"ID_1\", 1.00000001, 0, '2023-10-21'),\n        ('2', 3.4, \"ID_1\", 3.1, 123456, '2023-10-22'),\n        ('3', 4, \"ID\", 4, 4, '2023-10-22'),\n        ('4', 122345.54321, \"ID\", 122345.54321, 5, '2023-10-22');\"\"\")\nprint(cursor.fetchallarrow().to_pandas())\n"})}),"\n",(0,o.jsx)(r.p,{children:"The following proves that the import was successful:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"  StatusResult\n0            0\n"})}),"\n",(0,o.jsx)(r.p,{children:"If you need to import large amounts of data into Doris, you can use pydoris to perform Stream Load."}),"\n",(0,o.jsx)(r.h3,{id:"execute-a-query",children:"Execute a query"}),"\n",(0,o.jsx)(r.p,{children:"Then query the table imported above, including operations such as aggregation, sorting, and Set Session Variable."}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Python",children:'cursor.execute("select * from arrow_flight_sql_test order by k0;")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("set exec_mem_limit=2000;")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("show variables like \\"%exec_mem_limit%\\";")\nprint(cursor.fetchallarrow().to_pandas())\n\ncursor.execute("select k5, sum(k1), count(1), avg(k3) from arrow_flight_sql_test group by k5;")\nprint(cursor.fetchallarrow().to_pandas())\n'})}),"\n",(0,o.jsx)(r.p,{children:"The result is as follows:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{children:"   k0            k1    K2                k3          k4          k5\n0   0       0.10000    ID       0.000100000  9999999999  2023-10-21\n1   1       0.20000  ID_1       1.000000010           0  2023-10-21\n2   2       3.40000  ID_1       3.100000000      123456  2023-10-22\n3   3       4.00000    ID       4.000000000           4  2023-10-22\n4   4  122345.54321    ID  122345.543210000           5  2023-10-22\n\n[5 rows x 6 columns]\n\n  StatusResult\n0            0\n\n    Variable_name Value Default_Value Changed\n0  exec_mem_limit  2000    2147483648       1\n\n           k5  Nullable(Float64)_1  Int64_2 Nullable(Decimal(38, 9))_3\n0  2023-10-22         122352.94321        3            40784.214403333\n1  2023-10-21              0.30000        2                0.500050005\n\n[2 rows x 5 columns]\n"})}),"\n",(0,o.jsx)(r.h3,{id:"complete-code",children:"Complete code"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Python",children:'# Doris Arrow Flight SQL Test\n\n# step 1, library is released on PyPI and can be easily installed.\n# pip install adbc_driver_manager\n# pip install adbc_driver_flightsql\nimport adbc_driver_manager\nimport adbc_driver_flightsql.dbapi as flight_sql\n\n# step 2, create a client that interacts with the Doris Arrow Flight SQL service.\n# Modify arrow_flight_sql_port in fe/conf/fe.conf to an available port, such as 9090.\n# Modify arrow_flight_sql_port in be/conf/be.conf to an available port, such as 9091.\nconn = flight_sql.connect(uri="grpc://{FE_HOST}:{fe.conf:arrow_flight_sql_port}", db_kwargs={\n            adbc_driver_manager.DatabaseOptions.USERNAME.value: "root",\n            adbc_driver_manager.DatabaseOptions.PASSWORD.value: "",\n        })\ncursor = conn.cursor()\n\n# interacting with Doris via SQL using Cursor\ndef execute(sql):\n    print("\\n### execute query: ###\\n " + sql)\n    cursor.execute(sql)\n    print("### result: ###")\n    print(cursor.fetchallarrow().to_pandas())\n\n# step3, execute DDL statements, create database/table, show stmt.\nexecute("DROP DATABASE IF EXISTS arrow_flight_sql FORCE;")\nexecute("show databases;")\nexecute("create database arrow_flight_sql;")\nexecute("show databases;")\nexecute("use arrow_flight_sql;")\nexecute("""CREATE TABLE arrow_flight_sql_test\n    (\n         k0 INT,\n         k1 DOUBLE,\n         K2 varchar(32) NULL DEFAULT "" COMMENT "",\n         k3 DECIMAL(27,9) DEFAULT "0",\n         k4 BIGINT NULL DEFAULT \'10\',\n         k5 DATE,\n    )\n    DISTRIBUTED BY HASH(k5) BUCKETS 5\n    PROPERTIES("replication_num" = "1");""")\nexecute("show create table arrow_flight_sql_test;")\n\n\n# step4, insert into\nexecute("""INSERT INTO arrow_flight_sql_test VALUES\n        (\'0\', 0.1, "ID", 0.0001, 9999999999, \'2023-10-21\'),\n        (\'1\', 0.20, "ID_1", 1.00000001, 0, \'2023-10-21\'),\n        (\'2\', 3.4, "ID_1", 3.1, 123456, \'2023-10-22\'),\n        (\'3\', 4, "ID", 4, 4, \'2023-10-22\'),\n        (\'4\', 122345.54321, "ID", 122345.54321, 5, \'2023-10-22\');""")\n\n\n# step5, execute queries, aggregation, sort, set session variable\nexecute("select * from arrow_flight_sql_test order by k0;")\nexecute("set exec_mem_limit=2000;")\nexecute("show variables like \\"%exec_mem_limit%\\";")\nexecute("select k5, sum(k1), count(1), avg(k3) from arrow_flight_sql_test group by k5;")\n\n# step6, close cursor \ncursor.close()\n'})}),"\n",(0,o.jsx)(r.h2,{id:"jdbc-connector-with-arrow-flight-sql",children:"Jdbc Connector with Arrow Flight SQL"}),"\n",(0,o.jsx)(r.p,{children:"The open source JDBC driver of Arrow Flight SQL protocol is compatible with the standard JDBC API, which can be used by most BI tools to access Doris through JDBC and supports high-speed transmission of Apache Arrow data. The usage is similar to connecting to Doris through the JDBC driver of MySQL protocol. You only need to replace the jdbc:mysql protocol in the link URL with the jdbc:arrow-flight-sql protocol. The query results are still returned in the JDBC ResultSet data structure."}),"\n",(0,o.jsx)(r.p,{children:"POM dependency:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Java",children:"<properties>\n    <arrow.version>17.0.0</arrow.version>\n</properties>\n<dependencies>\n    <dependency>\n        <groupId>org.apache.arrow</groupId>\n        <artifactId>flight-sql-jdbc-core</artifactId>\n        <version>${arrow.version}</version>\n    </dependency>\n</dependencies>\n"})}),"\n",(0,o.jsx)(r.p,{children:"The connection code example is as follows:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Java",children:'import java.sql.Connection;\nimport java.sql.DriverManager;\nimport java.sql.ResultSet;\nimport java.sql.Statement;\n\nClass.forName("org.apache.arrow.driver.jdbc.ArrowFlightJdbcDriver");\nString DB_URL = "jdbc:arrow-flight-sql://{FE_HOST}:{fe.conf:arrow_flight_sql_port}?useServerPrepStmts=false"\n        + "&cachePrepStmts=true&useSSL=false&useEncryption=false";\nString USER = "root";\nString PASS = "";\n\nConnection conn = DriverManager.getConnection(DB_URL, USER, PASS);\nStatement stmt = conn.createStatement();\nResultSet resultSet = stmt.executeQuery("select * from information_schema.tables;");\nwhile (resultSet.next()) {\n    System.out.println(resultSet.toString());\n}\n\nresultSet.close();\nstmt.close();\nconn.close();\n'})}),"\n",(0,o.jsx)(r.h2,{id:"java-usage",children:"Java Usage"}),"\n",(0,o.jsx)(r.p,{children:"In addition to using JDBC, similar to Python, JAVA can also create a Driver to read Doris and return data in Arrow format. The following are how to use AdbcDriver and JdbcDriver to connect to Doris Arrow Flight Server."}),"\n",(0,o.jsx)(r.p,{children:"POM dependency:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Java",children:"<properties>\n    <adbc.version>0.12.0</adbc.version>\n</properties>\n\n<dependencies>\n    <dependency>\n        <groupId>org.apache.arrow.adbc</groupId>\n        <artifactId>adbc-driver-jdbc</artifactId>\n        <version>${adbc.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.arrow.adbc</groupId>\n        <artifactId>adbc-core</artifactId>\n        <version>${adbc.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.arrow.adbc</groupId>\n        <artifactId>adbc-driver-manager</artifactId>\n        <version>${adbc.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.arrow.adbc</groupId>\n        <artifactId>adbc-sql</artifactId>\n        <version>${adbc.version}</version>\n    </dependency>\n    <dependency>\n        <groupId>org.apache.arrow.adbc</groupId>\n        <artifactId>adbc-driver-flight-sql</artifactId>\n        <version>${adbc.version}</version>\n    </dependency>\n</dependencies>\n"})}),"\n",(0,o.jsx)(r.h3,{id:"adbc-driver",children:"ADBC Driver"}),"\n",(0,o.jsx)(r.p,{children:"The connection code example is as follows:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Java",children:'// 1. new driver\nfinal BufferAllocator allocator = new RootAllocator();\nFlightSqlDriver driver = new FlightSqlDriver(allocator);\nMap<String, Object> parameters = new HashMap<>();\nAdbcDriver.PARAM_URI.set(parameters, Location.forGrpcInsecure("{FE_HOST}", {fe.conf:arrow_flight_sql_port}).getUri().toString());\nAdbcDriver.PARAM_USERNAME.set(parameters, "root");\nAdbcDriver.PARAM_PASSWORD.set(parameters, "");\nAdbcDatabase adbcDatabase = driver.open(parameters);\n\n// 2. new connection\nAdbcConnection connection = adbcDatabase.connect();\nAdbcStatement stmt = connection.createStatement();\n\n// 3. execute query\nstmt.setSqlQuery("select * from information_schema.tables;");\nQueryResult queryResult = stmt.executeQuery();\nArrowReader reader = queryResult.getReader();\n\n// 4. load result\nList<String> result = new ArrayList<>();\nwhile (reader.loadNextBatch()) {\n    VectorSchemaRoot root = reader.getVectorSchemaRoot();\n    String tsvString = root.contentToTSVString();\n    result.add(tsvString);\n}\nSystem.out.printf("batchs %d\\n", result.size());\n\n// 5. close\nreader.close();\nqueryResult.close();\nstmt.close();\nconnection.close();\n'})}),"\n",(0,o.jsx)(r.h3,{id:"jdbc-driver",children:"JDBC Driver"}),"\n",(0,o.jsx)(r.p,{children:"When using Java 9 or later, some JDK internals must be exposed by adding --add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED to the java command:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-shell",children:'# Directly on the command line\n$ java --add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED -jar ...\n# Indirectly via environment variables\n$ env _JAVA_OPTIONS="--add-opens=java.base/java.nio=org.apache.arrow.memory.core,ALL-UNNAMED" java -jar ...\n'})}),"\n",(0,o.jsxs)(r.p,{children:["Otherwise, you may see some errors such as ",(0,o.jsx)(r.code,{children:'module java.base does not "opens java.nio" to unnamed module'})," or ",(0,o.jsx)(r.code,{children:'module java.base does not "opens java.nio" to org.apache.arrow.memory.core'})," or ",(0,o.jsx)(r.code,{children:"ava.lang.NoClassDefFoundError: Could not initialize class org.apache.arrow.memory.util.MemoryUtil (Internal; Prepare)"})]}),"\n",(0,o.jsxs)(r.p,{children:["If you debug in IntelliJ IDEA, you need to add ",(0,o.jsx)(r.code,{children:"--add-opens=java.base/java.nio=ALL-UNNAMED"})," in ",(0,o.jsx)(r.code,{children:"Build and run"})," of ",(0,o.jsx)(r.code,{children:"Run/Debug Configurations"}),", refer to the picture below:"]}),"\n",(0,o.jsx)(r.p,{children:(0,o.jsx)(r.img,{src:"https://github.com/user-attachments/assets/7439ee6d-9013-40bf-89af-0365925d3fdb",alt:"IntelliJ IDEA"})}),"\n",(0,o.jsx)(r.p,{children:"The connection code example is as follows:"}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-Java",children:'final Map<String, Object> parameters = new HashMap<>();\nAdbcDriver.PARAM_URI.set(\n        parameters,"jdbc:arrow-flight-sql://{FE_HOST}:{fe.conf:arrow_flight_sql_port}?useServerPrepStmts=false&cachePrepStmts=true&useSSL=false&useEncryption=false");\nAdbcDriver.PARAM_USERNAME.set(parameters, "root");\nAdbcDriver.PARAM_PASSWORD.set(parameters, "");\ntry (\n        BufferAllocator allocator = new RootAllocator();\n        AdbcDatabase db = new JdbcDriver(allocator).open(parameters);\n        AdbcConnection connection = db.connect();\n        AdbcStatement stmt = connection.createStatement()\n) {\n    stmt.setSqlQuery("select * from information_schema.tables;");\n    AdbcStatement.QueryResult queryResult = stmt.executeQuery();\n    ArrowReader reader = queryResult.getReader();\n    List<String> result = new ArrayList<>();\n    while (reader.loadNextBatch()) {\n        VectorSchemaRoot root = reader.getVectorSchemaRoot();\n        String tsvString = root.contentToTSVString();\n        result.add(tsvString);\n    }\n    long etime = System.currentTimeMillis();\n    System.out.printf("batchs %d\\n", result.size());\n\n    reader.close();\n    queryResult.close();\n    stmt.close();\n}  catch (Exception e) {\n    e.printStackTrace();\n}\n'})}),"\n",(0,o.jsx)(r.h3,{id:"choice-of-jdbc-and-java-connection-methods",children:"Choice of Jdbc and Java connection methods"}),"\n",(0,o.jsxs)(r.p,{children:[(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/blob/master/samples/arrow-flight-sql/java/README.md",children:"JDBC/Java Arrow Flight SQL Sample"})," is a JDBC/Java demo using Arrow FLight SQL. You can use it to test various connection methods for sending queries to Arrow Flight Server, helping you understand how to use Arrow FLight SQL and test performance. Implemented in ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/45306",children:"Add Arrow Flight Sql demo for Java"}),"."]}),"\n",(0,o.jsxs)(r.p,{children:["Compared with the traditional ",(0,o.jsx)(r.code,{children:"jdbc:mysql"})," connection method, the performance test of the Arrow Flight SQL connection method of Jdbc and Java can be found in Section 6.2 of ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/issues/25514",children:"GitHub Issue"}),". Here are some usage suggestions based on the test conclusions."]}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsx)(r.p,{children:"For the above three Java Arrow Flight SQL connection methods, if the subsequent data analysis will be based on the row-based data format, then use jdbc:arrow-flight-sql, which will return data in the JDBC ResultSet format; if the subsequent data analysis can be based on the Arrow format or other column-based data formats, then use Flight AdbcDriver or Flight JdbcDriver to directly return data in the Arrow format, which will avoid row-column conversion and use the characteristics of Arrow to accelerate data parsing."}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Whether parsing data in JDBC ResultSet or Arrow format, the time spent is longer than the time spent reading data. If the performance of Arrow Flight SQL is not as expected and the improvement is limited compared with ",(0,o.jsx)(r.code,{children:"jdbc:mysql://"}),", you may want to analyze whether it takes too long to parse the data."]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsx)(r.p,{children:"For all connection methods, JDK 17 reads data faster than JDK 1.8."}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["When reading a large amount of data, Arrow Flight SQL will use less memory than ",(0,o.jsx)(r.code,{children:"jdbc:mysql://"}),", so if you are troubled by insufficient memory, you can also try Arrow Flight SQL."]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsx)(r.p,{children:"In addition to the above three connection methods, you can also use the native FlightClient to connect to Arrow Flight Server, which can read multiple endpoints in parallel more flexibly. Flight AdbcDriver is also a link created based on FlightClient, which is simpler than using FlightClient directly."}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(r.h2,{id:"interaction-with-other-big-data-components",children:"Interaction with other big data components"}),"\n",(0,o.jsx)(r.h3,{id:"spark--flink",children:"Spark & \u200B\u200BFlink"}),"\n",(0,o.jsxs)(r.p,{children:["Arrow Flight currently has no official plan to support Spark and Flink (",(0,o.jsx)(r.a,{href:"https://github.com/apache/arrow-adbc/issues/1490",children:"GitHub Issue"}),"). Since version 24.0.0, Doris' own ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris-spark-connector",children:"Spark Connector"})," and ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris-flink-connector",children:"Flink Connector"})," have supported accessing Doris via Arrow Flight SQL, and it is expected that this will improve the reading performance several times."]}),"\n",(0,o.jsxs)(r.p,{children:["The community previously referred to the open source ",(0,o.jsx)(r.a,{href:"https://github.com/qwshen/spark-flight-connector",children:"Spark-Flight-Connector"})," and used FlightClient in Spark to connect to Doris for testing. It was found that the data format conversion between Arrow and Doris Block is faster, which is 10 times the conversion speed between CSV format and Doris Block, and it has better support for complex types such as Map and Array. This is because the Arrow data format has a high compression rate and low network overhead during transmission. However, Doris Arrow Flight has not yet implemented multi-node parallel reading. It still aggregates query results to a BE node and returns them. For simple batch export of data, the performance may not be as fast as Doris Spark Connector, which supports Tablet-level parallel reading. If you want to use Arrow Flight SQL to connect to Doris in Spark, you can refer to the open-sourced ",(0,o.jsx)(r.a,{href:"https://github.com/qwshen/spark-flight-connector",children:"Spark-Flight-Connector"})," and ",(0,o.jsx)(r.a,{href:"https://github.com/dremio-hub/dremio-flight-connector",children:"Dremio-Flight-Connector"})," to implement it yourself."]}),"\n",(0,o.jsx)(r.h3,{id:"support-bi-tools",children:"Support BI tools"}),"\n",(0,o.jsxs)(r.p,{children:["Since Doris v2.1.8, BI tools such as DBeaver are supported to connect to Doris using the ",(0,o.jsx)(r.code,{children:"arrow-flight-sql"})," protocol. For DBeaver's method of connecting to Doris using the ",(0,o.jsx)(r.code,{children:"arrow-flight-sql"})," Driver, refer to: ",(0,o.jsx)(r.a,{href:"https://www.dremio.com/blog/jdbc-driver-for-arrow-flight-sql/#h-how-to-use-jdbc-driver-with-dbeaver-client",children:"how-to-use-jdbc-driver-with-dbeaver-client"}),", ",(0,o.jsx)(r.a,{href:"https://docs.dremio.com/current/sonar/client-applications/clients/dbeaver/?_gl=1*1epgwh0*_gcl_au*MjUyNjE1ODM0LjE3MzQwMDExNDg",children:"client-applications/clients/dbeaver/"}),"."]}),"\n",(0,o.jsx)(r.h2,{id:"extended-application",children:"Extended Application"}),"\n",(0,o.jsx)(r.h3,{id:"multiple-bes-return-results-in-parallel",children:"Multiple BEs return results in parallel"}),"\n",(0,o.jsx)(r.p,{children:"Doris will aggregate the results of a query on all BE nodes to one BE node by default. In Mysql/JDBC queries, FE will request query results from this aggregated data node. In Arrow Flight SQL queries, FE will wrap the IP/Port of this node in the Endpoint and return it to ADBC \u200B\u200BClient. ADBC \u200B\u200BClient will request the BE node corresponding to this Endpoint to pull data."}),"\n",(0,o.jsx)(r.p,{children:"If the query is just a simple Select to pull data from Doris, without Join, Sort, Window Function and other operators with data Shuffle behavior, the query can be split according to Tablet granularity. Now Doris Spark/Flink Connector uses this method to implement parallel data reading, which is divided into two steps:"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["Execute ",(0,o.jsx)(r.code,{children:"explain sql"}),", and the ScanOperator in the query plan returned by FE contains all Tablet ID Lists of Scan."]}),"\n",(0,o.jsxs)(r.li,{children:["Split the original SQL into multiple SQLs based on the Tablet ID List above. Each SQL only reads part of the Tablet. The usage is similar to ",(0,o.jsx)(r.code,{children:"SELECT * FROM t1 TABLET(10001,10002) limit 1000;"}),". The multiple SQLs after splitting can be executed in parallel. Refer to ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/10170",children:"Support select table sample"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["If the outermost layer of the query is aggregation, the SQL is similar to ",(0,o.jsx)(r.code,{children:"select k1, sum(k2) from xxx group by k1"}),". After Doris v3.4, execute ",(0,o.jsx)(r.code,{children:"set enable_parallel_result_sink=true;"})," to allow each BE node of a query to return query results independently. After receiving the Endpoint list returned by FE, ADBC \u200B\u200BClient pulls results from multiple BE nodes in parallel. However, please note that when the aggregation result is very small, returning multiple BEs will increase the pressure on RPC. For specific implementation, please refer to ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/36053",children:"support parallel result sink"}),". In theory, except for the outermost query which is sorted, other queries can support each BE node to return results in parallel, but there is no need for this convenience at present, and no further implementation has been made."]}),"\n",(0,o.jsx)(r.h3,{id:"multiple-bes-share-the-same-ip-accessible-from-outside-the-cluster",children:"Multiple BEs share the same IP accessible from outside the cluster"}),"\n",(0,o.jsx)(r.p,{children:"If there is a Doris cluster, its FE node can be accessed from outside the cluster, and all its BE nodes can only be accessed from inside the cluster. This is fine when using Mysql Client and JDBC to connect to Doris to execute queries, and the query results will be returned by the Doris FE node. However, using Arrow Flight SQL to connect to Doris cannot execute queries, because ADBC \u200B\u200BClient needs to connect to the Doris BE node to pull query results, but the Doris BE node is not allowed to be accessed from outside the cluster."}),"\n",(0,o.jsx)(r.p,{children:"In a production environment, it is often inconvenient to expose the Doris BE node outside the cluster. However, you can add a reverse proxy (such as Nginx) to all Doris BE nodes. When the client outside the cluster connects to Nginx, it will be randomly routed to a Doris BE node. By default, the Arrow Flight SQL query results will be randomly saved on a Doris BE node. If it is different from the Doris BE node randomly routed by Nginx, data forwarding is required within the Doris BE node."}),"\n",(0,o.jsxs)(r.p,{children:["Starting from Doris v2.1.8, you can configure ",(0,o.jsx)(r.code,{children:"public_host"})," and ",(0,o.jsx)(r.code,{children:"arrow_flight_sql_proxy_port"})," in ",(0,o.jsx)(r.code,{children:"be.conf"})," of all Doris BE nodes to the IP and port shared by multiple Doris BE nodes and accessible outside the cluster. The query results can be correctly forwarded and returned to the ADBC \u200B\u200BClient."]}),"\n",(0,o.jsx)(r.pre,{children:(0,o.jsx)(r.code,{className:"language-conf",children:"public_host={nginx ip}\narrow_flight_sql_proxy_port={nginx port}\n"})}),"\n",(0,o.jsx)(r.h2,{id:"faq",children:"FAQ"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["Q: ARM environment reports an error ",(0,o.jsx)(r.code,{children:"get flight info statement failed, arrow flight schema timeout, TimeoutException: Waited 5000 milliseconds for io.grpc.stub.Client"}),"."]}),"\n"]}),"\n",(0,o.jsx)(r.p,{children:"A: If the Linux kernel version is <= 4.19.90, you need to upgrade to 4.19.279 or above, or recompile Doris BE in the environment of the lower version of the Linux kernel. For specific compilation methods, refer to the document <docs/dev/install/source-install/compilation-arm>"}),"\n",(0,o.jsxs)(r.p,{children:["Cause: This is because there is a compatibility issue between the old version of the Linux kernel and Arrow. ",(0,o.jsx)(r.code,{children:"cpp: arrow::RecordBatch::MakeEmpty()"})," will get stuck when constructing Arrow Record Batch, causing Doris BE's Arrow Flight Server to fail to respond to Doris FE's Arrow Flight Server's RPC request within 5000ms, causing FE to return rpc timeout failed to Client. When Spark and Flink read Doris, they also convert the query results into Arrow Record Batch and return them, so the same problem exists."]}),"\n",(0,o.jsx)(r.p,{children:"The Linux kernel version of kylinv10 SP2 and SP3 is only 4.19.90-24.4.v2101.ky10.aarch64 at most. The kernel version cannot be upgraded further. Doris BE can only be recompiled on kylinv10. If the problem still exists after compiling Doris BE with the new version of ldb_toolchain, you can try to compile it with the lower version of ldb_toolchain v0.17. If your ARM environment cannot connect to the external network, Huawei Cloud provides ARM + kylinv10, and Alibaba Cloud provides x86 + kylinv10"}),"\n",(0,o.jsxs)(r.ol,{start:"2",children:["\n",(0,o.jsx)(r.li,{children:"Q: Prepared statement passes parameters and reports errors."}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: Currently, ",(0,o.jsx)(r.code,{children:"jdbc:arrow-flight-sql"})," and Java ADBC/JDBCDriver do not support prepared statement parameter passing. For example, ",(0,o.jsx)(r.code,{children:"select * from xxx where id=?"})," will report an error ",(0,o.jsx)(r.code,{children:"parameter ordinal 1 out of range"}),". This is a bug in Arrow Flight SQL (",(0,o.jsx)(r.a,{href:"https://github.com/apache/arrow/issues/40118",children:"GitHub Issue"}),")."]}),"\n",(0,o.jsxs)(r.ol,{start:"3",children:["\n",(0,o.jsxs)(r.li,{children:["Q: How to modify the batch size read by ",(0,o.jsx)(r.code,{children:"jdbc:arrow-flight-sql"})," each time to improve performance in some scenarios."]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: By modifying ",(0,o.jsx)(r.code,{children:"setTargetBatchSize"})," in the ",(0,o.jsx)(r.code,{children:"makeJdbcConfig"})," method in the ",(0,o.jsx)(r.code,{children:"org.apache.arrow.adbc.driver.jdbc.JdbcArrowReader"})," file, the default is 1024, and then saving the modified file to the local directory with the same path name, so as to overwrite the original file and take effect."]}),"\n",(0,o.jsxs)(r.ol,{start:"4",children:["\n",(0,o.jsx)(r.li,{children:"Q: ADBC \u200B\u200Bv0.10, JDBC and Java ADBC/JDBCDriver do not support parallel reading."}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: The ",(0,o.jsx)(r.code,{children:"stmt.executePartitioned()"})," method is not implemented. You can only use the native FlightClient to implement parallel reading of multiple endpoints, using the method ",(0,o.jsx)(r.code,{children:"sqlClient=new FlightSqlClient, execute=sqlClient.execute(sql), endpoints=execute.getEndpoints(), for(FlightEndpoint endpoint: endpoints)"}),". In addition, the default AdbcStatement of ADBC \u200B\u200BV0.10 is actually JdbcStatement. After executeQuery, the row-format JDBC ResultSet is converted back to the Arrow column format. It is expected that Java ADBC \u200B\u200Bwill be fully functional by ADBC \u200B\u200B1.0.0 ",(0,o.jsx)(r.a,{href:"https://github.com/apache/arrow-adbc/issues/1490",children:"GitHub Issue"}),"."]}),"\n",(0,o.jsxs)(r.ol,{start:"5",children:["\n",(0,o.jsx)(r.li,{children:"Q: Specify the database name in the URL."}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: As of Arrow v15.0, Arrow JDBC Connector does not support specifying database name in URL. For example, specifying connection to ",(0,o.jsx)(r.code,{children:"test"})," database in ",(0,o.jsx)(r.code,{children:"jdbc:arrow-flight-sql://{FE_HOST}:{fe.conf:arrow_flight_sql_port}/test?useServerPrepStmts=false"})," is invalid, and you can only execute SQL ",(0,o.jsx)(r.code,{children:"use database"})," manually. Arrow v18.0 supports specifying database name in URL, but there are still bugs in actual testing."]}),"\n",(0,o.jsxs)(r.ol,{start:"6",children:["\n",(0,o.jsxs)(r.li,{children:["Q: Python ADBC \u200B\u200Bprints ",(0,o.jsx)(r.code,{children:"Warning: Cannot disable autocommit; conn will not be DB-API 2.0 compliant"}),"."]}),"\n"]}),"\n",(0,o.jsx)(r.p,{children:"A: Ignore this Warning when using Python. This is a problem with Python ADBC \u200B\u200BClient and will not affect queries."}),"\n",(0,o.jsxs)(r.ol,{start:"7",children:["\n",(0,o.jsxs)(r.li,{children:["Q: Python reports an error ",(0,o.jsx)(r.code,{children:"grpc: received message larger than max (20748753 vs. 16777216)"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: Refer to ",(0,o.jsx)(r.a,{href:"https://github.com/apache/arrow-adbc/issues/2078",children:"Python: grpc: received message larger than max (20748753 vs. 16777216) #2078"})," and add ",(0,o.jsx)(r.code,{children:"adbc_driver_flightsql.DatabaseOptions.WITH_MAX_MSG_SIZE.value"})," in Database Option."]}),"\n",(0,o.jsxs)(r.ol,{start:"8",children:["\n",(0,o.jsxs)(r.li,{children:["Q: Error ",(0,o.jsx)(r.code,{children:"invalid bearer token"})," is reported."]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: Execute ",(0,o.jsx)(r.code,{children:"SET PROPERTY FOR 'root' 'max_user_connections' = '10000';"})," to change the current maximum number of connections for the current user to 10000; add qe_max_connection=30000 and arrow_flight_token_cache_size=8000 in ",(0,o.jsx)(r.code,{children:"fe.conf"})," and restart FE."]}),"\n",(0,o.jsxs)(r.p,{children:["The connection between the ADBC \u200B\u200BClient and the Arrow Flight Server is essentially a long link, which requires Auth Token, Connection, and Session to be cached on the Server. After the connection is created, it will not be disconnected immediately at the end of a single query. The Client needs to send a close() request to clean it up, but in fact, the Client often does not send a close request, so the Auth Token, Connection, and Session will be saved on the Arrow Flight Server for a long time. By default, they will time out and disconnect after 3 days, or be eliminated according to LRU after the number of connections exceeds the limit of ",(0,o.jsx)(r.code,{children:"arrow_flight_token_cache_size"}),"."]}),"\n",(0,o.jsxs)(r.p,{children:["As of Doris v2.1.8, Arrow Flight connections and Mysql/JDBC connections use the same connection limit, including the total number of connections of all FE users ",(0,o.jsx)(r.code,{children:"qe_max_connection"})," and the number of connections of a single user ",(0,o.jsx)(r.code,{children:"max_user_connections"})," in ",(0,o.jsx)(r.code,{children:"UserProperty"}),". But the default ",(0,o.jsx)(r.code,{children:"qe_max_connection"})," and ",(0,o.jsx)(r.code,{children:"max_user_connections"})," are 1024 and 100 respectively. Arrow Flight SQL is often used to replace JDBC scenarios, but the JDBC connection will be released immediately after the query ends. Therefore, when using Arrow Flight SQL, the default connection limit of Doris is too small, which often causes the connection number to exceed the limit of ",(0,o.jsx)(r.code,{children:"arrow_flight_token_cache_size"})," and the connections still in use to be eliminated."]}),"\n",(0,o.jsxs)(r.ol,{start:"9",children:["\n",(0,o.jsx)(r.li,{children:"Q: Java Arrow Flight SQL reads the Datatime type and returns a timestamp instead of the formatted time."}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: Java Arrow Flight SQL needs to convert the timestamp by itself when reading the Datatime type. Refer to ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/48578",children:"Add java parsing datetime type in arrow flight sql sample #48578"}),". Using Python Arrow Flight SQL to read the Datatime type returns ",(0,o.jsx)(r.code,{children:"2025-03-03 17:23:28Z"}),", while Java Arrow Flight SQL returns ",(0,o.jsx)(r.code,{children:"1740993808"}),"."]}),"\n",(0,o.jsxs)(r.ol,{start:"10",children:["\n",(0,o.jsxs)(r.li,{children:["Q: Java Arrow Flight JDBC Client reports an error ",(0,o.jsx)(r.code,{children:"Configuration does not provide a mapping for array column 2"})," when reading Array nested types."]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["A: Refer to ",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/blob/master/samples/arrow-flight-sql/java/src/main/java/doris/arrowflight/demo/FlightAdbcDriver.java",children:(0,o.jsx)(r.code,{children:"sample/arrow-flight-sql"})})," to use JAVA ADBC \u200B\u200BClient."]}),"\n",(0,o.jsx)(r.p,{children:"Python ADBC \u200B\u200BClient, JAVA ADBC \u200B\u200BClient, and Java JDBC DriverManager all have no problem reading Array nested types. Only Java Arrow Flight JDBC Client has problems. In fact, the compatibility of Arrow Flight JDBC Client is not guaranteed. It is not officially developed by Arrow, but by a third-party database company Dremio. Other compatibility issues have been found before, so it is recommended to use JAVA ADBC \u200B\u200BClient first."}),"\n",(0,o.jsx)(r.h2,{id:"release-note",children:"Release Note"}),"\n",(0,o.jsxs)(r.blockquote,{children:["\n",(0,o.jsx)(r.p,{children:"Arrow Flight SQL protocol is supported since Doris 2.1. As of Doris 2.1.9, the issues fixed are listed based on Doris 2.1 series versions. Doris 3.0 series versions are self-checked."}),"\n"]}),"\n",(0,o.jsx)(r.h3,{id:"v219",children:"v2.1.9"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["Fix the problem of Doris data serialization to Arrow.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/48944",children:"Fix UT DataTypeSerDeArrowTest of Array/Map/Struct/Bitmap/HLL/Decimal256 types"})]}),"\n"]}),"\n",(0,o.jsxs)(r.ul,{children:["\n",(0,o.jsxs)(r.li,{children:["Failed to read ",(0,o.jsx)(r.code,{children:"Decimal256"})," type;"]}),"\n",(0,o.jsxs)(r.li,{children:["Subtle error in reading ",(0,o.jsx)(r.code,{children:"DatetimeV2"})," type;"]}),"\n",(0,o.jsxs)(r.li,{children:["Incorrect result in reading ",(0,o.jsx)(r.code,{children:"DateV2"})," type;"]}),"\n",(0,o.jsxs)(r.li,{children:["Error when reading ",(0,o.jsx)(r.code,{children:"IPV4/IPV6"})," type result is NULL;"]}),"\n"]}),"\n",(0,o.jsxs)(r.ol,{start:"2",children:["\n",(0,o.jsxs)(r.li,{children:["Fix the problem that Doris Arrow Flight SQL query fails and returns empty result, without returning real error information.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/45023",children:"Fix query result is empty and not return query error message"})]}),"\n"]}),"\n",(0,o.jsx)(r.h3,{id:"v218",children:"v2.1.8"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Support BI tools such as DBeaver to connect to Doris using the ",(0,o.jsx)(r.code,{children:"arrow-flight-sql"})," protocol, and support the correct display of metadata trees.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/46217",children:"Support arrow-flight-sql protocol getStreamCatalogs, getStreamSchemas, getStreamTables #46217"}),"."]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["When multiple BEs share the same IP that is accessible to the outside of the cluster, the query results can be correctly forwarded and returned to the ADBC \u200B\u200BClient.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/43281",children:"Arrow flight server supports data forwarding when BE uses public vip"})]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Support multiple endpoints to read in parallel.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/44286",children:"Arrow Flight support multiple endpoints"})]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix query error ",(0,o.jsx)(r.code,{children:"FE not found arrow flight schema"}),".\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/43960",children:"Fix FE not found arrow flight schema"})]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix error ",(0,o.jsx)(r.code,{children:"BooleanBuilder::AppendValues"})," when reading columns that allow NULL.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/43929",children:"Fix Doris NULL column conversion to arrow batch"})]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix ",(0,o.jsx)(r.code,{children:"show processlist"})," displays duplicate Connection IDs.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/46284",children:"Fix arrow-flight-sql ConnectContext to use a unified ID #46284"})]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(r.h3,{id:"v217",children:"v2.1.7"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix frequent log printing ",(0,o.jsx)(r.code,{children:"Connection wait_timeout"}),".\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/41770",children:"Fix kill timeout FlightSqlConnection and FlightSqlConnectProcessor close"})]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix Arrow Flight Bearer Token expiration from Cache.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/41754",children:"Fix Arrow Flight bearer token cache evict after expired"})]}),"\n"]}),"\n"]}),"\n",(0,o.jsx)(r.h3,{id:"v216",children:"v2.1.6"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix query error ",(0,o.jsx)(r.code,{children:"0.0.0.0:xxx, connection refused"}),".\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/40002",children:"Fix return result from FE Arrow Flight server error 0.0.0.0:xxx, connection refused"})]}),"\n"]}),"\n",(0,o.jsxs)(r.li,{children:["\n",(0,o.jsxs)(r.p,{children:["Fix query error ",(0,o.jsx)(r.code,{children:"Reach limit of connections"}),".\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/39127",children:"Fix exceed user property max connection cause Reach limit of connections #39127"})]}),"\n"]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["In previous versions, execute ",(0,o.jsx)(r.code,{children:"SET PROPERTY FOR 'root' 'max_user_connections' = '1024';"})," to modify the current maximum number of connections for the current user to 1024, which can be temporarily circumvented."]}),"\n",(0,o.jsxs)(r.p,{children:["Because the previous version only limits the number of Arrow Flight connections to less than ",(0,o.jsx)(r.code,{children:"qe_max_connection/2"}),", ",(0,o.jsx)(r.code,{children:"qe_max_connection"})," is the total number of connections for all fe users, the default is 1024, and does not limit the number of Arrow Flight connections for a single user to less than ",(0,o.jsx)(r.code,{children:"max_user_connections"})," in ",(0,o.jsx)(r.code,{children:"UserProperty"}),", the default is 100, so when the number of Arrow Flight connections exceeds the upper limit of the current user's connection number, an error ",(0,o.jsx)(r.code,{children:"Reach limit of connections"})," will be reported, so the current user's ",(0,o.jsx)(r.code,{children:"max_user_connections"})," needs to be increased."]}),"\n",(0,o.jsxs)(r.p,{children:["For details of the problem, see: ",(0,o.jsx)(r.a,{href:"https://ask.selectdb.com/questions/D18b1/2-1-4-ban-ben-python-shi-yong-arrow-flight-sql-lian-jie-bu-hui-duan-kai-lian-jie-shu-zhan-man-da-dao-100/E1ic1?commentId=10070000000005324",children:"Questions"})]}),"\n",(0,o.jsxs)(r.ol,{start:"3",children:["\n",(0,o.jsxs)(r.li,{children:["Add Conf ",(0,o.jsx)(r.code,{children:"arrow_flight_result_sink_buffer_size_rows"})," to support modifying the ArrowBatch size of query results returned in a single time, the default is 4096 * 8.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/38221",children:"Add config arrow_flight_result_sink_buffer_size_rows"})]}),"\n"]}),"\n",(0,o.jsx)(r.h3,{id:"v215",children:"v2.1.5"}),"\n",(0,o.jsxs)(r.ol,{children:["\n",(0,o.jsxs)(r.li,{children:["Fix the problem that Arrow Flight SQL query results are empty.\n",(0,o.jsx)(r.a,{href:"https://github.com/apache/doris/pull/36827",children:"Fix arrow flight result sink #36827"})]}),"\n"]}),"\n",(0,o.jsxs)(r.p,{children:["Doris v2.1.4 may report an error when reading large amounts of data. For details, see: ",(0,o.jsx)(r.a,{href:"https://ask.selectdb.com/questions/D1Ia1/arrow-flight-sql-shi-yong-python-de-adbc-driver-lian-jie-doris-zhi-xing-cha-xun-sql-du-qu-bu-dao-shu-ju",children:"Questions"})]}),"\n",(0,o.jsx)(r.h3,{id:"doris-arrow-flight-v214-and-earlier-versions-are-not-perfect-it-is-recommended-to-upgrade-before-use",children:"Doris Arrow Flight v2.1.4 and earlier versions are not perfect. It is recommended to upgrade before use."})]})}function h(e={}){let{wrapper:r}={...(0,i.a)(),...e.components};return r?(0,o.jsx)(r,{...e,children:(0,o.jsx)(d,{...e})}):d(e)}},347174:function(e,r,n){n.d(r,{Z:function(){return t}});let t=n.p+"assets/images/Arrow_Flight_SQL-c51538bca23f1062d141adab8fe055cb.png"},250065:function(e,r,n){n.d(r,{Z:function(){return a},a:function(){return s}});var t=n(667294);let o={},i=t.createContext(o);function s(e){let r=t.useContext(i);return t.useMemo(function(){return"function"==typeof e?e(r):{...r,...e}},[r,e])}function a(e){let r;return r=e.disableParentContext?"function"==typeof e.components?e.components(o):e.components||o:s(e.components),t.createElement(i.Provider,{value:r},e.children)}}}]);